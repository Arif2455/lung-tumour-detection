{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1+QWIZyKkw9vtJrLjMSzz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arif2455/lung-tumour-detection/blob/main/LungTumourDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 2: create folder structure ===\n",
        "import os, shutil, math\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "class_a_dir = os.path.join(DATA_DIR, CLASS_A_NAME)\n",
        "class_b_dir = os.path.join(DATA_DIR, CLASS_B_NAME)\n",
        "os.makedirs(class_a_dir, exist_ok=True)\n",
        "os.makedirs(class_b_dir, exist_ok=True)\n",
        "print(\"Created folders:\")\n",
        "print(\" -\", class_a_dir)\n",
        "print(\" -\", class_b_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SrQa7prQmoO",
        "outputId": "aeff4f39-06a5-4812-a8e2-64244a606ac1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created folders:\n",
            " - /content/lung_project/normal\n",
            " - /content/lung_project/tumour\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egmr3GSOLSWx",
        "outputId": "7f5d3a8b-5413-4d32-b21e-060edd4661b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 246 image files in /content\n",
            "First 40 filenames:\n",
            "  1. JPCLN001.png\n",
            "  2. JPCLN002.png\n",
            "  3. JPCLN003.png\n",
            "  4. JPCLN004.png\n",
            "  5. JPCLN005.png\n",
            "  6. JPCLN006.png\n",
            "  7. JPCLN007.png\n",
            "  8. JPCLN008.png\n",
            "  9. JPCLN009.png\n",
            " 10. JPCLN010.png\n",
            " 11. JPCLN011.png\n",
            " 12. JPCLN012.png\n",
            " 13. JPCLN013.png\n",
            " 14. JPCLN014.png\n",
            " 15. JPCLN015.png\n",
            " 16. JPCLN016.png\n",
            " 17. JPCLN017.png\n",
            " 18. JPCLN018.png\n",
            " 19. JPCLN019.png\n",
            " 20. JPCLN020.png\n",
            " 21. JPCLN021.png\n",
            " 22. JPCLN022.png\n",
            " 23. JPCLN023.png\n",
            " 24. JPCLN024.png\n",
            " 25. JPCLN025.png\n",
            " 26. JPCLN026.png\n",
            " 27. JPCLN027.png\n",
            " 28. JPCLN028.png\n",
            " 29. JPCLN029.png\n",
            " 30. JPCLN030.png\n",
            " 31. JPCLN031.png\n",
            " 32. JPCLN032.png\n",
            " 33. JPCLN033.png\n",
            " 34. JPCLN034.png\n",
            " 35. JPCLN035.png\n",
            " 36. JPCLN036.png\n",
            " 37. JPCLN037.png\n",
            " 38. JPCLN038.png\n",
            " 39. JPCLN039.png\n",
            " 40. JPCLN040.png\n"
          ]
        }
      ],
      "source": [
        "# === Cell 1: configure these variables ===\n",
        "UPLOAD_DIR = \"/content\"            # where your loose images currently are (change if different)\n",
        "DATA_DIR   = \"/content/lung_project\"  # target dataset folder we'll create\n",
        "CLASS_A_NAME = \"normal\"            # change if you want different names\n",
        "CLASS_B_NAME = \"tumour\"\n",
        "CLASS_A_COUNT = 154                # number of images you want in CLASS_A\n",
        "CLASS_B_COUNT = 93                 # number of images you want in CLASS_B\n",
        "SPLIT_MODE = \"by_count\"            # options: \"by_count\", \"by_pattern\", \"by_csv\"\n",
        "\n",
        "# === Helper & quick preview ===\n",
        "import pathlib, os\n",
        "IMG_EXTS = {'.jpg','.jpeg','.png','.bmp','.tif','.tiff'}\n",
        "p = pathlib.Path(UPLOAD_DIR)\n",
        "all_imgs = [str(x) for x in sorted(p.glob(\"*\")) if x.suffix.lower() in IMG_EXTS]\n",
        "\n",
        "print(f\"Found {len(all_imgs)} image files in {UPLOAD_DIR}\")\n",
        "print(\"First 40 filenames:\")\n",
        "for i,fn in enumerate(all_imgs[:40], 1):\n",
        "    print(f\"{i:3d}. {os.path.basename(fn)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "4cb3b061",
        "outputId": "14dd812c-8eb5-4726-a941-474fb47946d1"
      },
      "source": [
        "# === Cell 3A: Auto split by count ===\n",
        "if SPLIT_MODE != \"by_count\":\n",
        "    print(\"Skipping by_count (SPLIT_MODE != 'by_count').\")\n",
        "else:\n",
        "    imgs = all_imgs.copy()\n",
        "    total_needed = CLASS_A_COUNT + CLASS_B_COUNT\n",
        "    if len(imgs) < total_needed:\n",
        "        raise SystemExit(f\"Not enough images found ({len(imgs)}) for requested counts ({total_needed}).\")\n",
        "    # Move first N to class A, next M to class B\n",
        "    a_list = imgs[:CLASS_A_COUNT]\n",
        "    b_list = imgs[CLASS_A_COUNT:CLASS_A_COUNT+CLASS_B_COUNT]\n",
        "\n",
        "    import shutil, os\n",
        "    for src in a_list:\n",
        "        dst = os.path.join(class_a_dir, os.path.basename(src))\n",
        "        shutil.move(src, dst)\n",
        "    for src in b_list:\n",
        "        dst = os.path.join(class_b_dir, os.path.basename(src))\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "    print(f\"Moved {len(a_list)} → {class_a_dir}\")\n",
        "    print(f\"Moved {len(b_list)} → {class_b_dir}\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "Not enough images found (246) for requested counts (247).",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Not enough images found (246) for requested counts (247).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "\n",
        "CLASS_A_NAME = \"normal\"\n",
        "CLASS_B_NAME = \"tumour\"\n",
        "CLASS_A_COUNT = 153   # adjust so A+B = total\n",
        "CLASS_B_COUNT = 93\n",
        "\n",
        "# Source = all loose images in /content\n",
        "IMG_EXTS = {'.jpg','.jpeg','.png','.bmp','.tif','.tiff'}\n",
        "import pathlib\n",
        "UPLOAD_DIR = \"/content\"\n",
        "all_imgs = [str(x) for x in sorted(pathlib.Path(UPLOAD_DIR).glob(\"*\")) if x.suffix.lower() in IMG_EXTS]\n",
        "\n",
        "print(f\"Total images found: {len(all_imgs)}\")\n",
        "\n",
        "# Make folders\n",
        "DATA_DIR = \"/content/lung_project\"\n",
        "os.makedirs(os.path.join(DATA_DIR, CLASS_A_NAME), exist_ok=True)\n",
        "os.makedirs(os.path.join(DATA_DIR, CLASS_B_NAME), exist_ok=True)\n",
        "\n",
        "# Split\n",
        "a_list = all_imgs[:CLASS_A_COUNT]\n",
        "b_list = all_imgs[CLASS_A_COUNT:CLASS_A_COUNT+CLASS_B_COUNT]\n",
        "\n",
        "for src in a_list:\n",
        "    dst = os.path.join(DATA_DIR, CLASS_A_NAME, os.path.basename(src))\n",
        "    shutil.move(src, dst)\n",
        "\n",
        "for src in b_list:\n",
        "    dst = os.path.join(DATA_DIR, CLASS_B_NAME, os.path.basename(src))\n",
        "    shutil.move(src, dst)\n",
        "\n",
        "print(f\"✅ Moved {len(a_list)} images → {CLASS_A_NAME}\")\n",
        "print(f\"✅ Moved {len(b_list)} images → {CLASS_B_NAME}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74yUbaoXTmHR",
        "outputId": "dc8986dd-67e5-4141-8751-9ac29a70712a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images found: 246\n",
            "✅ Moved 153 images → normal\n",
            "✅ Moved 93 images → tumour\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "for folder in pathlib.Path(DATA_DIR).iterdir():\n",
        "    if folder.is_dir():\n",
        "        count = len(list(folder.glob(\"*\")))\n",
        "        print(f\"{folder.name}: {count} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfSDfGQNTm-d",
        "outputId": "b9901ca4-f435-47d0-afed-8ac955845848"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tumour: 93 images\n",
            "normal: 153 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    validation_split=0.2, # 80% train, 20% val\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Cache + prefetch for performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Build simple CNN\n",
        "model = keras.Sequential([\n",
        "    layers.Rescaling(1./255, input_shape=(224,224,3)),\n",
        "    layers.Conv2D(32, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBFNUyO9T4r7",
        "outputId": "d18110e2-f7f1-416a-8dcd-640396987eae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 246 files belonging to 2 classes.\n",
            "Using 197 files for training.\n",
            "Found 246 files belonging to 2 classes.\n",
            "Using 49 files for validation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.4732 - loss: 1.1181 - val_accuracy: 0.5714 - val_loss: 0.6856\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6065 - loss: 0.6685 - val_accuracy: 0.5714 - val_loss: 0.6851\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6220 - loss: 0.6758 - val_accuracy: 0.5714 - val_loss: 0.7009\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5892 - loss: 0.6845 - val_accuracy: 0.5714 - val_loss: 0.7623\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6337 - loss: 0.6682 - val_accuracy: 0.5714 - val_loss: 0.6925\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6464 - loss: 0.6552 - val_accuracy: 0.5714 - val_loss: 0.6835\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5897 - loss: 0.6766 - val_accuracy: 0.5714 - val_loss: 0.7099\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6373 - loss: 0.6409 - val_accuracy: 0.5714 - val_loss: 0.6888\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.6263 - loss: 0.6403 - val_accuracy: 0.5714 - val_loss: 0.6823\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6579 - loss: 0.6028 - val_accuracy: 0.5510 - val_loss: 0.7093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = \"/content/lung_tumour_model.h5\"\n",
        "model.save(MODEL_PATH)\n",
        "print(\"✅ Model saved at:\", MODEL_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmSIKvfmT-bw",
        "outputId": "69769d4a-2ebb-4f08-eea1-e7afd90e92e2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved at: /content/lung_tumour_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Tumour samples:\")\n",
        "print(os.listdir(\"/content/lung_project/tumour\")[:5])\n",
        "\n",
        "print(\"\\nNormal samples:\")\n",
        "print(os.listdir(\"/content/lung_project/normal\")[:5])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9_l4Nr5VCJz",
        "outputId": "e2f47e18-0c2f-46b5-fc3b-0c667cdb39b8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tumour samples:\n",
            "['JPCNN066.png', 'JPCNN054.png', 'JPCNN020.png', 'JPCNN037.png', 'JPCNN082.png']\n",
            "\n",
            "Normal samples:\n",
            "['JPCLN096.png', 'JPCLN079.png', 'JPCLN021.png', 'JPCLN146.png', 'JPCLN019.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Tumour samples:\", os.listdir(\"/content/lung_project/tumour\")[:10])\n",
        "print(\"\\nNormal samples:\", os.listdir(\"/content/lung_project/normal\")[:10])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL8d6RKmVD52",
        "outputId": "ded30d95-10e7-4e3a-90a2-e7685f50b862"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tumour samples: ['JPCNN066.png', 'JPCNN054.png', 'JPCNN020.png', 'JPCNN037.png', 'JPCNN082.png', 'JPCNN089.png', 'JPCNN091.png', 'JPCNN033.png', 'JPCNN043.png', 'JPCNN006.png']\n",
            "\n",
            "Normal samples: ['JPCLN096.png', 'JPCLN079.png', 'JPCLN021.png', 'JPCLN146.png', 'JPCLN019.png', 'JPCLN069.png', 'JPCLN020.png', 'JPCLN077.png', 'JPCLN042.png', 'JPCLN091.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Tumour samples:\")\n",
        "print(os.listdir(\"/content/lung_project/tumour\")[:10])\n",
        "\n",
        "print(\"\\nNormal samples:\")\n",
        "print(os.listdir(\"/content/lung_project/normal\")[:10])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGT3ZHkkVQi0",
        "outputId": "356c78f8-b349-4462-9536-ea1558747347"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tumour samples:\n",
            "['JPCNN066.png', 'JPCNN054.png', 'JPCNN020.png', 'JPCNN037.png', 'JPCNN082.png', 'JPCNN089.png', 'JPCNN091.png', 'JPCNN033.png', 'JPCNN043.png', 'JPCNN006.png']\n",
            "\n",
            "Normal samples:\n",
            "['JPCLN096.png', 'JPCLN079.png', 'JPCLN021.png', 'JPCLN146.png', 'JPCLN019.png', 'JPCLN069.png', 'JPCLN020.png', 'JPCLN077.png', 'JPCLN042.png', 'JPCLN091.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test tumour\n",
        "test_img = \"/content/lung_project/tumour/JPCNN066.png\"\n",
        "print(\"Tumour test:\", predict_image(test_img))\n",
        "\n",
        "# Test normal\n",
        "test_img = \"/content/lung_project/normal/JPCLN096.png\"\n",
        "print(\"Normal test:\", predict_image(test_img))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv8qHNHuVerS",
        "outputId": "e7375840-1629-43e1-99dd-c0fb58a9284e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
            "Tumour test: ('Normal', np.float32(0.20936929))\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "Normal test: ('Normal', np.float32(0.21083398))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(500).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Data augmentation\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "# Pretrained base model\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224,224,3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False  # freeze feature extractor\n",
        "\n",
        "# Build model\n",
        "model = keras.Sequential([\n",
        "    data_augmentation,\n",
        "    layers.Rescaling(1./255),\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "MODEL_PATH = \"/content/lung_tumour_mobilenet.h5\"\n",
        "model.save(MODEL_PATH)\n",
        "print(\"✅ Transfer learning model saved at:\", MODEL_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAvNlT6NVj2I",
        "outputId": "5eea4379-d0e0-4699-89eb-3cd62a19e813"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 246 files belonging to 2 classes.\n",
            "Using 197 files for training.\n",
            "Found 246 files belonging to 2 classes.\n",
            "Using 49 files for validation.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.6395 - loss: 0.7207 - val_accuracy: 0.5714 - val_loss: 0.6454\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 768ms/step - accuracy: 0.6504 - loss: 0.6677 - val_accuracy: 0.5918 - val_loss: 0.7027\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 771ms/step - accuracy: 0.6329 - loss: 0.7084 - val_accuracy: 0.6122 - val_loss: 0.6783\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 782ms/step - accuracy: 0.6579 - loss: 0.6217 - val_accuracy: 0.6327 - val_loss: 0.6673\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 679ms/step - accuracy: 0.6320 - loss: 0.6476 - val_accuracy: 0.6531 - val_loss: 0.6386\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 908ms/step - accuracy: 0.6244 - loss: 0.6581 - val_accuracy: 0.6735 - val_loss: 0.6316\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 773ms/step - accuracy: 0.6118 - loss: 0.6342 - val_accuracy: 0.6122 - val_loss: 0.6615\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 772ms/step - accuracy: 0.6202 - loss: 0.7192 - val_accuracy: 0.6122 - val_loss: 0.6506\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 684ms/step - accuracy: 0.6434 - loss: 0.6306 - val_accuracy: 0.6327 - val_loss: 0.6535\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 773ms/step - accuracy: 0.7373 - loss: 0.5983 - val_accuracy: 0.6327 - val_loss: 0.6462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Transfer learning model saved at: /content/lung_tumour_mobilenet.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_image(\"/content/lung_project/tumour/JPCNN066.png\"))\n",
        "print(predict_image(\"/content/lung_project/normal/JPCLN096.png\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sftE-4SnVzGs",
        "outputId": "a43e7905-bdd2-42e5-bb06-3e391b294f2b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "('Tumour', np.float32(0.65461606))\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
            "('Tumour', np.float32(0.65422356))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "\n",
        "# Load model\n",
        "MODEL_PATH = \"lung_tumour_mobilenet.h5\"\n",
        "model = tf.keras.models.load_model(MODEL_PATH)\n",
        "IMG_SIZE = (224,224)\n",
        "\n",
        "st.title(\"🫁 Lung Tumour Detection App\")\n",
        "st.write(\"Upload a lung scan image to classify as **Tumour** or **Normal**.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\",\"png\",\"jpeg\"])\n",
        "\n",
        "def predict_image(img):\n",
        "    img = load_img(img, target_size=IMG_SIZE)\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    pred = model.predict(img_array)[0][0]\n",
        "    label = \"Tumour\" if pred > 0.5 else \"Normal\"\n",
        "    return label, pred\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    st.image(uploaded_file, caption=\"Uploaded Image\", use_column_width=True)\n",
        "    label, score = predict_image(uploaded_file)\n",
        "    st.write(f\"### Prediction: {label}\")\n",
        "    st.write(f\"Confidence Score: {float(score):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "Ew1bu44uWWor",
        "outputId": "e99b12c7-06eb-4e9e-e496-7b0c07206485"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3042538140.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLItX2k_WZBR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}